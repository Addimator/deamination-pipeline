configfile: "config/config.yaml"

accession = config["accession"]
genome_config = config["sample"]


rule all:
    input:
        "results/assigned_bases.txt"

rule get_genome:
    output:
        "resources/genome.fasta",
    params:
        species=genome_config["species"],
        datatype=genome_config["datatype"],
        build=genome_config["build"],
        release=genome_config["release"],
    log:
        "logs/get_genome.log",
    cache: "omit-software"  # save space and time with between workflow caching (see docs)
    wrapper:
        "v2.3.2/bio/reference/ensembl-sequence"

rule genome_index:
    input:
        "resources/genome.fasta",
    output:
        "resources/genome.fasta.fai",
    log:
        "logs/genome_index.log",
    conda:
        "envs/samtools.yaml"
    params:
        pipeline_path=config["pipeline_path"],
    shell:
        """ 
        samtools faidx {params.pipeline_path}{input}
        """


rule find_candidates:
    input:
        "resources/genome.fasta",
    output:
        "resources/candidates.bcf",
    log:
        "logs/find_candidates.log",
    conda:
        "envs/varlociraptor.yaml"
    params:
        varlo_path=config["varlo_path"],
        pipeline_path=config["pipeline_path"],
    shell:
        """ 
        cd {params.varlo_path}
        cargo run -- methylation-candidates {params.pipeline_path}{input} {params.pipeline_path}{output}
        """

rule candidates_to_vcf:
    input:
        "resources/candidates.bcf",
    output:
        "resources/candidates.vcf",
    conda:
        "envs/samtools.yaml"
    log:
        "logs/convert_to_vcf.log",
    shell:
        """
        bcftools view {input} > {output}
        """

rule get_fastq_pe:
    output:
        # the wildcard name must be accession, pointing to an SRA number
        "resources/{accession}_1.fastq",
        "resources/{accession}_2.fastq",
    log:
        "logs/pe/{accession}.log"
    params:
        extra="--skip-technical"
    threads: 6  # defaults to 6
    conda:
        "envs/fastq-wrapper.yaml"
    wrapper:
        "v2.6.0/bio/sra-tools/fasterq-dump"


rule align_reads:
    input:
        fasta="resources/genome.fasta",
        reads1=expand("resources/{accession}_1.fastq", accession=accession),
        reads2=expand("resources/{accession}_2.fastq", accession=accession),
    output:
        "resources/aligned-reads.sam",
    conda:
        "envs/bwa-mem2.yaml"
    log:
        "logs/align_reads.log",
    shell:
        """
        bwa-mem2 index {input.fasta}
        bwa-mem2 {input.fasta} {input.reads1} {input.reads2} | gzip -3 > aln-pe.sam.gz
        """

rule find_bases:
    input:
        aligned_reads="resources/aligned-reads.sam",
        candidates="resources/candidates.vcf",
    output:
        "resources/pos_to_bases.txt",
    conda:
        "envs/varlociraptor.yaml"
    params:
        pipeline_path=config["pipeline_path"],
    log:
        "logs/find_bases.log",
    shell:
        """
        cd {params.pipeline_path}workflow/scripts
        cargo run  -- find-bases {params.pipeline_path}{input.aligned_reads} {params.pipeline_path}{input.candidates} {params.pipeline_path}{output}
       """

rule download_bedGraphs:
    output:
        "resources/HG002/{bedGraph}.bedGraph.gz",
    log:
        "logs/download_bedGraphs{bedGraph}.log",
    params:
        pipeline_path=config["pipeline_path"],
        bedGraphs = config["bedGraphs_HG002"]
    script:
        "scripts/get_bedGraph_data.py"


rule process_data:
    input:
        "resources/HG002/{bedGraph}.bedGraph.gz"
    output:
        "resources/HG002/{bedGraph}.bedGraph"
    log:
        "logs/process_data{bedGraph}.log",
    shell:
        "gunzip -c {input} > {output}"


rule compute_avg_bedGraph:
    input:
        # expand("resources/HG002/bedGraph/{bed}.bedGraph", bed=bedGraphs),
        expand("resources/HG002/{bedGraph}.bedGraph", bedGraph=config["bedGraphs_HG002"])

    output:
        "resources/bed_avg.bedGraph",
    log:
        "logs/compute_avg_bedGraph.log",
    script:
        "scripts/compute_avg_bedGraph.py"



rule assign_bases:
    input:
        bedGraph="resources/bed_avg.bedGraph",
        ref_bases="resources/pos_to_bases.txt",
    output:
        "results/assigned_bases.txt"
    conda:
        "envs/varlociraptor.yaml"
    params:
        pipeline_path=config["pipeline_path"],
    log:
        "logs/assign_bases.log",
    shell:
        """
        cd {params.pipeline_path}workflow/scripts
        cargo run  -- assign-bases {params.pipeline_path}{input.bedGraph} {params.pipeline_path}{input.ref_bases} {params.pipeline_path}{output}
        """